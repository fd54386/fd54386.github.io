---
layout: post
title: First Post
---
After spending a couple of years lurking on the datascience subreddit, it's pretty clear to me that the scope-of-work for a datascientist is going to change depending on who you ask.  However the exact job description and pay grade shakes out, data scientists are the folks trying to navigate the 21st Century intersection of three things:

1) Data is available in volumes far larger than ever before, and we're still trying to figure out all of the applications for it.  What are the applications? Are there new datastreams that would facilitate work already being done?  This is where domain knowledge comes into play, identifying where the most value is for data.
2) What's the best way to use that data? Is it a one-off analysis? Classic applications for statistical methods are focused on characterizing uncertainty from small sample sizes where each datapoint has a significant cost.  Deep learning and other models that capitalize on computing power and large datasets can easily trade that uncertainty characterization for better predictive power. What's needed for the application? 
3) As easy as some tools make it to write a couple lines of code and hit 'run' on a model, is it going to generate an output in a timeframe that's usable?  Is more computing power cost effective? Is there more efficient code that can be run? Or is there a simpler model that still gets good enough results?  Software Engineering experience helps answer these questions.

My own experience with data mostly straddles items 1) and 2).  I come from working in a highly dynamic manufacturing environment where there's far more data available than there are process engineers to digest it.  If a new yield signal showed up recently, what's the right model to characterize it?  Can we, with statistical confidence, locate the offending manufacturing step? Once we have answers from data, what's the next step?  Do we shut the line down or sign up for a long-term project to improve it?  The data science field is interesting, because there are always new uses for the data we're already collecting.
